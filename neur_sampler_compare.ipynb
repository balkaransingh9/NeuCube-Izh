{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "rna_data = pd.read_csv(\"gene_data/rna_common_complete.csv\")\n",
    "rna_data = rna_data.sort_values(by=['sn','period']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_og_shape = rna_data.drop(['sn','group','caarms_status','period'],axis=1).values\n",
    "X_reshaped = X_og_shape.reshape(len(set(rna_data['sn'])), 3, X_og_shape.shape[1])\n",
    "labels_group = rna_data[rna_data['period'] == 24]['group'].values\n",
    "labels = [0 if i == 'C' else 1 for i in labels_group]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from neucube.utils import SNR\n",
    "from neucube.utils import interpolate\n",
    "from neucube.encoder import Delta\n",
    "\n",
    "ratios = SNR(X_reshaped[:,0,:], labels)\n",
    "top_idx = torch.argsort(ratios, descending=True)[0:20]\n",
    "X_reshaped_topidx = X_reshaped[:,:,top_idx]\n",
    "interpolated_X = interpolate(X_reshaped_topidx, num_points=104)\n",
    "\n",
    "encoder = Delta(threshold=0.008)\n",
    "X = encoder.encode_dataset(interpolated_X)\n",
    "y = torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_parm_dict = { \n",
    "    'rs' : {'a': 0.02, 'b': 0.2, 'c': -65, 'd': 8}, \n",
    "    'ch' : {'a': 0.02, 'b': 0.55, 'c': -45, 'd': 4},\n",
    "    'ib' : {'a': 0.06, 'b': 0.55, 'c': -55, 'd': 3},\n",
    "    'fs' : {'a': 0.1, 'b': 0.2, 'c': -65, 'd': 2},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from tqdm import tqdm\n",
    "\n",
    "from neucube import IzhReservoir, Reservoir\n",
    "from neucube.sampler import SpikeCount, MeanFiringRate, TemporalBinning, ISIstats, DeSNN\n",
    "from neucube.utils import SeparationIndex\n",
    "\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds)\n",
    "\n",
    "samplers = [SpikeCount(), MeanFiringRate(), TemporalBinning(bin_size=10), ISIstats(), DeSNN()]\n",
    "sampler_names = ['Spike Count', 'Mean Firing Rate', 'Temporal Binning', 'ISI Stats', 'DeSNN']\n",
    "neuron_types = ['rs', 'ch', 'ib', 'mix']\n",
    "\n",
    "result_dict_full = {}\n",
    "result_dict_avg = {}\n",
    "\n",
    "for n_type in neuron_types:\n",
    "    sampler_results_full = {}\n",
    "    sampler_results_avg = {}\n",
    "    print(f\"Neuron Type: {n_type}\")\n",
    "    for sampler, s_names in zip(samplers, sampler_names):\n",
    "        print(f\"Sampler: {s_names}\")\n",
    "        true_labels = []\n",
    "        predicted_labels = []\n",
    "        separation_values = []\n",
    "        sampler_acc_fold = []\n",
    "        sampler_mcc_fold = []\n",
    "        for train_index, test_index in tqdm(kf.split(X)):\n",
    "            X_train_fold, X_test_fold = X[train_index], X[test_index]\n",
    "            y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "\n",
    "            izh_res = IzhReservoir(inputs=X.shape[2], c=0.7, l=0.18, input_conn_prob=0.85)\n",
    "            if n_type == 'mix':\n",
    "                init_n_type = np.random.choice(['rs','ch','ib'], izh_res.n_neurons, replace=True)\n",
    "                fs_indices = np.random.choice(len(init_n_type), int(0.2 * len(init_n_type)), replace=False)\n",
    "                init_n_type[fs_indices] = 'fs'\n",
    "                a, b, c, d = [torch.tensor(list(map(lambda x: neuron_parm_dict[x][i], init_n_type))) for i in ['a', 'b', 'c', 'd']]\n",
    "                izh_res.update_parms(a=a, b=b, c=c, d=d)\n",
    "            else:\n",
    "                izh_res.set_exc_parms(**neuron_parm_dict[n_type])\n",
    "                #izh_res.set_inh_parms(a=0.01, b=0.2, c=-65, d=8)\n",
    "                izh_res.set_inh_parms(a=0.1, b=0.2, c=-65, d=2)\n",
    "\n",
    "            X_train_opt_spike = izh_res.simulate(X_train_fold, mem_thr=30, train=False, verbose=False)\n",
    "            X_test_opt_spike = izh_res.simulate(X_test_fold, mem_thr=30, train=False, verbose=False)\n",
    "            X_train_state_vec = sampler.sample(X_train_opt_spike)\n",
    "            X_test_state_vec = sampler.sample(X_test_opt_spike)\n",
    "\n",
    "            param_grid = {'C': [2, 3, 4, 5, 6, 7, 8], 'gamma': [0.1, 0.01, 0.001], 'kernel': ['rbf', 'linear', 'poly']}\n",
    "            svm_model = svm.SVC()\n",
    "            mcc_scorer = make_scorer(metrics.matthews_corrcoef)\n",
    "            grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=10, scoring={'accuracy': 'accuracy', 'mcc': mcc_scorer}, refit='mcc')\n",
    "            grid_search.fit(X_train_state_vec, y_train_fold)\n",
    "            y_pred = grid_search.best_estimator_.predict(X_test_state_vec)\n",
    "\n",
    "            true_labels.extend(y_test_fold)\n",
    "            predicted_labels.extend(y_pred)\n",
    "            separation_values.append([SeparationIndex(X_train_state_vec, y_train_fold), SeparationIndex(X_test_state_vec, y_test_fold)])\n",
    "            sampler_acc_fold.append(accuracy_score(y_test_fold, y_pred))\n",
    "            sampler_mcc_fold.append(metrics.matthews_corrcoef(y_test_fold, y_pred))\n",
    "        \n",
    "        sampler_results_full[s_names] = {'accuracy': sampler_acc_fold, 'mcc': sampler_mcc_fold, 'separation': separation_values}\n",
    "        sampler_results_avg[s_names] = {'accuracy': np.mean(sampler_acc_fold), 'mcc': np.mean(sampler_mcc_fold)}\n",
    "        #update sampler_results dict here\n",
    "        #make it possible to select acc, mcc\n",
    "    #update result_dict here\n",
    "    result_dict_full[n_type] = sampler_results_full\n",
    "    result_dict_avg[n_type] = sampler_results_avg\n",
    "\n",
    "        # Calculate accuracy\n",
    "        # accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "        # print(\"10-Fold Cross-Validation Accuracy:\", accuracy)\n",
    "        # print(confusion_matrix(true_labels, predicted_labels))\n",
    "pd.DataFrame(result_dict_full).to_csv('result_full.csv', sep='|', index=False)\n",
    "pd.DataFrame(result_dict_avg).to_csv('result_avg.csv', sep='|', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
