{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "28nNT0lHxZv5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "rna_data = pd.read_csv(\"rna_common_complete.csv\")\n",
        "rna_data = rna_data.sort_values(by=['sn','period']).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bOT9UpVkxZv9"
      },
      "outputs": [],
      "source": [
        "X_og_shape = rna_data.drop(['sn','group','caarms_status','period'],axis=1).values\n",
        "X_reshaped = X_og_shape.reshape(len(set(rna_data['sn'])), 3, X_og_shape.shape[1])\n",
        "labels_group = rna_data[rna_data['period'] == 24]['group'].values\n",
        "labels = [0 if i == 'C' else 1 for i in labels_group]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "su6AzPKbxZv-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from neucube.utils import SNR\n",
        "from neucube.utils import interpolate\n",
        "from neucube.encoder import Delta\n",
        "\n",
        "ratios = SNR(X_reshaped[:,0,:], labels)\n",
        "top_idx = torch.argsort(ratios, descending=True)[0:20]\n",
        "X_reshaped_topidx = X_reshaped[:,:,top_idx]\n",
        "interpolated_X = interpolate(X_reshaped_topidx, num_points=104)\n",
        "\n",
        "encoder = Delta(threshold=0.008)\n",
        "X = encoder.encode_dataset(interpolated_X)\n",
        "y = torch.tensor(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bwM7HGtCxZv_"
      },
      "outputs": [],
      "source": [
        "import nevergrad as ng\n",
        "import numpy as np\n",
        "from functools import partial\n",
        "from neucube.sampler import TemporalBinning\n",
        "from neucube.utils import SeparationIndex\n",
        "from tqdm import tqdm\n",
        "\n",
        "neuron_parm_dict = {\n",
        "    'ffs': {'a': 0.1, 'b': 0.2, 'c': -65, 'd': 8},\n",
        "    'ibfs': {'a': 0.02, 'b': 1, 'c': -65, 'd': 8},\n",
        "    'ibvfs': {'a': 0.02, 'b': 1, 'c': -65, 'd': 2},\n",
        "    'ms': {'a': 0.03, 'b': 0.2, 'c': -65, 'd': 8},\n",
        "    'mch': {'a': 0.05, 'b': 0.2, 'c': -50, 'd': 4},\n",
        "    'rs': {'a': 0.02, 'b': 0.2, 'c': -65, 'd': 8},\n",
        "    'ib': {'a': 0.02, 'b': 0.2, 'c': -55, 'd': 4},\n",
        "    'ch': {'a': 0.02, 'b': 0.2, 'c': -50, 'd': 2},\n",
        "    'vfs': {'a': 1, 'b': 0.4, 'c': -65, 'd': 2},\n",
        "}\n",
        "\n",
        "def objective_function(res_, X_stimuli, labels, params, sampler):\n",
        "    params = torch.nn.functional.softmax(torch.tensor(params), dim=0).numpy()\n",
        "    print(params)\n",
        "    n_type = np.random.choice(['ffs','ch','mch','ibfs','rs'], izh_res.n_neurons, replace=True, p=params)\n",
        "    a, b, c, d = [torch.tensor(list(map(lambda x: neuron_parm_dict[x][i], n_type))) for i in ['a', 'b', 'c', 'd']]\n",
        "    izh_res.update_parms(a=a, b=b, c=c, d=d)\n",
        "    out_spikes = res_.simulate(X_stimuli, mem_thr=30, train=False, verbose=False)\n",
        "    state_vec = sampler.sample(out_spikes)\n",
        "    return np.round(SeparationIndex(state_vec, labels).item(), 5)\n",
        "\n",
        "def run_opt(optimizer, objective_):\n",
        "    for i in range(optimizer.budget):\n",
        "        x = optimizer.ask()\n",
        "        loss = -objective_(params=x.value)\n",
        "        optimizer.tell(x, loss)\n",
        "        if (i + 1) % 2 == 0:\n",
        "            print(f\"Iteration {i + 1}/{optimizer.budget}, Current loss: {loss}\")\n",
        "\n",
        "def train_dyanmics(reservoir_, X_, y_, sampler_):\n",
        "    instrumentation = ng.p.Array(shape=(5,))#.set_bounds(0, 1)\n",
        "\n",
        "    optimizer = ng.optimizers.TwoPointsDE(parametrization=instrumentation, budget=50, num_workers=1)\n",
        "    partial_objective_function = partial(objective_function, res_=reservoir_, X_stimuli=X_, labels=y_, sampler=sampler_)\n",
        "\n",
        "    run_opt(optimizer, partial_objective_function)\n",
        "    recommendation = optimizer.provide_recommendation()\n",
        "    return recommendation.value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOT13VcgxZwA",
        "outputId": "fb9e7798-7263-4294-fd14-0b2d717cbdea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.49832896 0.00810037 0.08040706 0.03526498 0.37789863]\n",
            "[0.01140512 0.03769752 0.89877574 0.02025139 0.03187023]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn import svm, metrics\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "from neucube import IzhReservoir\n",
        "from neucube.sampler import TemporalBinning, SpikeCount\n",
        "from neucube.utils import SeparationIndex\n",
        "\n",
        "num_folds = 10\n",
        "kf = KFold(n_splits=num_folds)\n",
        "sampler = TemporalBinning(bin_size=10)\n",
        "\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "separation_values = []\n",
        "accuracy_values = []\n",
        "mcc_values = []\n",
        "\n",
        "for train_index, test_index in tqdm(kf.split(X)):\n",
        "    X_train_fold, X_test_fold = X[train_index], X[test_index]\n",
        "    y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
        "\n",
        "    izh_res = IzhReservoir(inputs=X.shape[2], c=0.7, l=0.18, input_conn_prob=0.85)\n",
        "    opt_parms = train_dyanmics(izh_res, X_train_fold, y_train_fold, sampler)\n",
        "\n",
        "    opt_parms = torch.nn.functional.softmax(torch.tensor(opt_parms), dim=0).numpy()\n",
        "    n_type = np.random.choice(['ffs','ch','mch','ibfs','rs'], izh_res.n_neurons, replace=True, p=opt_parms)\n",
        "    a, b, c, d = [torch.tensor(list(map(lambda x: neuron_parm_dict[x][i], n_type))) for i in ['a', 'b', 'c', 'd']]\n",
        "    izh_res.update_parms(a=a, b=b, c=c, d=d)\n",
        "    print(pd.Series(n_type).value_counts())\n",
        "    X_train_opt_spike = izh_res.simulate(X_train_fold, mem_thr=30, train=False, verbose=False)\n",
        "    X_test_opt_spike = izh_res.simulate(X_test_fold, mem_thr=30, train=False, verbose=False)\n",
        "    X_train_state_vec = sampler.sample(X_train_opt_spike)\n",
        "    X_test_state_vec = sampler.sample(X_test_opt_spike)\n",
        "\n",
        "    param_grid = {'C': [2, 3, 4, 5, 6, 7, 8], 'gamma': [0.1, 0.01, 0.001], 'kernel': ['rbf', 'linear', 'poly']}\n",
        "    svm_model = svm.SVC()\n",
        "    mcc_scorer = make_scorer(metrics.matthews_corrcoef)\n",
        "    grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=10, scoring={'accuracy': 'accuracy', 'mcc': mcc_scorer}, refit='accuracy')\n",
        "    grid_search.fit(X_train_state_vec, y_train_fold)\n",
        "    y_pred = grid_search.best_estimator_.predict(X_test_state_vec)\n",
        "\n",
        "    true_labels.extend(y_test_fold)\n",
        "    predicted_labels.extend(y_pred)\n",
        "    separation_values.extend([SeparationIndex(X_train_state_vec, y_train_fold), SeparationIndex(X_test_state_vec, y_test_fold)])\n",
        "    accuracy_values.append(accuracy_score(y_test_fold, y_pred))\n",
        "    mcc_values.append(metrics.matthews_corrcoef(y_test_fold, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "p07bEeBUxZwB"
      },
      "outputs": [],
      "source": [
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "mcc = metrics.matthews_corrcoef(true_labels, predicted_labels)\n",
        "print(\"10-Fold Cross-Validation Accuracy:\", accuracy)\n",
        "print(\"10-Fold Cross-Validation MCC:\", mcc)\n",
        "print(confusion_matrix(true_labels, predicted_labels))\n",
        "print(accuracy_values)\n",
        "print(mcc_values)\n",
        "print(separation_values)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
