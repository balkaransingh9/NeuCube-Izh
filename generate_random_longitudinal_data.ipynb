{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def generate_complex_trends(n_timesteps, n_features, trend_type='mixed', randomness=0.1, seed=None):\n",
    "    \"\"\"\n",
    "    Generate complex trends for features over time with added randomness.\n",
    "\n",
    "    Parameters:\n",
    "    - n_timesteps: int, number of time steps\n",
    "    - n_features: int, number of features\n",
    "    - trend_type: str, type of trend ('sin', 'exp', 'poly', or 'mixed')\n",
    "    - randomness: float, level of randomness to add to the trends\n",
    "    - seed: int or None, random seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "    - trends: np.ndarray, generated trends\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    else:\n",
    "        np.random.seed(None)  # Set a random seed if not provided\n",
    "\n",
    "    time = np.linspace(0, 1, n_timesteps)\n",
    "    trends = np.zeros((n_timesteps, n_features))\n",
    "\n",
    "    for i in range(n_features):\n",
    "        if trend_type == 'sin':\n",
    "            trends[:, i] = np.sin(2 * np.pi * (i + 1) * time)\n",
    "        elif trend_type == 'exp':\n",
    "            trends[:, i] = np.exp(time * (i + 1))\n",
    "        elif trend_type == 'poly':\n",
    "            trends[:, i] = time ** (i + 1)\n",
    "        elif trend_type == 'mixed':\n",
    "            trends[:, i] = (np.sin(2 * np.pi * (i + 1) * time) + \n",
    "                            np.exp(time * (i + 1)) - \n",
    "                            time ** (i + 1))\n",
    "        else:\n",
    "            raise ValueError(\"Unknown trend type. Choose from 'sin', 'exp', 'poly', or 'mixed'.\")\n",
    "        \n",
    "        trends[:, i] += randomness * np.random.randn(n_timesteps)\n",
    "    \n",
    "    return trends\n",
    "\n",
    "def generate_longitudinal_data(n_samples=1000, n_timesteps=10, n_features=5, n_redundant_features=3, class_sep=1.0, trend_type='mixed', randomness=0.1, seed=None):\n",
    "    \"\"\"\n",
    "    Generate longitudinal classification data with complex trends, time dependencies, and added randomness.\n",
    "\n",
    "    Parameters:\n",
    "    - n_samples: int, number of samples\n",
    "    - n_timesteps: int, number of time steps\n",
    "    - n_features: int, number of relevant features\n",
    "    - n_redundant_features: int, number of redundant features\n",
    "    - class_sep: float, parameter to adjust the separability of classes\n",
    "    - trend_type: str, type of trend ('sin', 'exp', 'poly', or 'mixed')\n",
    "    - randomness: float, level of randomness to add to the trends\n",
    "    - seed: int or None, random seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "    - data: pd.DataFrame, generated data\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    else:\n",
    "        np.random.seed(None)\n",
    "\n",
    "    data = []\n",
    "    class_trends = {\n",
    "        0: generate_complex_trends(n_timesteps, n_features, trend_type, randomness, seed),\n",
    "        1: generate_complex_trends(n_timesteps, n_features, trend_type, randomness, seed)\n",
    "    }\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        class_label = np.random.choice([0, 1])\n",
    "        \n",
    "        base_signal = np.random.randn(n_features)\n",
    "        \n",
    "        class_offset = class_label * class_sep\n",
    "        \n",
    "        time_series = []\n",
    "\n",
    "        for t in range(n_timesteps):\n",
    "            trend = class_trends[class_label][t, :]\n",
    "            noise = np.random.randn(n_features) * (1 - class_sep)\n",
    "            time_features = base_signal + class_offset + trend + noise\n",
    "            \n",
    "            redundant_features = np.random.randn(n_redundant_features)\n",
    "            combined_features = np.concatenate([time_features, redundant_features])\n",
    "            time_series.append(combined_features)\n",
    "\n",
    "        sample_data = pd.DataFrame(time_series, columns=[f'feature_{j}' for j in range(n_features + n_redundant_features)])\n",
    "        sample_data['time'] = range(n_timesteps)\n",
    "        sample_data['class'] = class_label\n",
    "        sample_data['sample_id'] = i\n",
    "        data.append(sample_data)\n",
    "\n",
    "    data = pd.concat(data, ignore_index=True)    \n",
    "    return data\n",
    "\n",
    "# Visualize the dataset\n",
    "def visualize_samples(data, n_samples=5):\n",
    "    sample_ids = np.random.choice(data['sample_id'].unique(), n_samples, replace=False)\n",
    "    for sample_id in sample_ids:\n",
    "        sample_data = data[data['sample_id'] == sample_id]\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        for feature in sample_data.columns[:-3]:\n",
    "            plt.plot(sample_data['time'], sample_data[feature], label=feature)\n",
    "        plt.title(f'Sample ID: {sample_id}, Class: {sample_data[\"class\"].iloc[0]}')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Feature Value')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "def prepare_data_for_classification(data, n_timesteps=10):\n",
    "    feature_cols = [col for col in data.columns if 'feature' in col]\n",
    "    agg_data = data.groupby(['sample_id', 'class'])[feature_cols].agg(['mean', 'std']).reset_index()\n",
    "    agg_data.columns = ['_'.join(col).strip() for col in agg_data.columns.values]\n",
    "    agg_data = agg_data.rename(columns={'sample_id_': 'sample_id', 'class_': 'class'})\n",
    "    return agg_data\n",
    "\n",
    "# Extract features from the first time step\n",
    "def extract_first_timestep_features(data, n_timesteps=10):\n",
    "    feature_cols = [col for col in data.columns if 'feature' in col]\n",
    "    first_timestep_data = data[data['time'] == 0].groupby(['sample_id', 'class'])[feature_cols].first().reset_index()\n",
    "    return first_timestep_data\n",
    "\n",
    "def split_data(agg_data, first_timestep_data):\n",
    "    X_agg = agg_data.drop(columns=['sample_id', 'class'])\n",
    "    y_agg = agg_data['class']\n",
    "    X_train_agg, X_test_agg, y_train_agg, y_test_agg = train_test_split(X_agg, y_agg, test_size=0.2, random_state=42)\n",
    "\n",
    "    X_first = first_timestep_data.drop(columns=['sample_id', 'class'])\n",
    "    y_first = first_timestep_data['class']\n",
    "    X_train_first, X_test_first, y_train_first, y_test_first = train_test_split(X_first, y_first, test_size=0.2, random_state=42)\n",
    "    \n",
    "    return X_train_agg, X_test_agg, y_train_agg, y_test_agg, X_train_first, X_test_first, y_train_first, y_test_first\n",
    "\n",
    "def evaluate_classifier(X_train, X_test, y_train, y_test):\n",
    "    classifier = RandomForestClassifier(random_state=42)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "for class_sep in [0.1, 0.5, 1.0, 1.5]:\n",
    "    print(f\"\\nClass Separation: {class_sep}\")\n",
    "    seed = np.random.randint(0, 10000)\n",
    "    data = generate_longitudinal_data(n_samples=100, n_timesteps=100, n_features=10, n_redundant_features=5, class_sep=class_sep, trend_type='mixed', randomness=0.1, seed=seed)\n",
    "    \n",
    "    #visualize_samples(data)\n",
    "    \n",
    "    agg_data = prepare_data_for_classification(data)\n",
    "    first_timestep_data = extract_first_timestep_features(data)\n",
    "    X_train_agg, X_test_agg, y_train_agg, y_test_agg, X_train_first, X_test_first, y_train_first, y_test_first = split_data(agg_data, first_timestep_data)\n",
    "    \n",
    "    accuracy_agg = evaluate_classifier(X_train_agg, X_test_agg, y_train_agg, y_test_agg)\n",
    "    accuracy_first = evaluate_classifier(X_train_first, X_test_first, y_train_first, y_test_first)\n",
    "    \n",
    "    print(f'Accuracy with aggregated features: {accuracy_agg:.2f}')\n",
    "    print(f'Accuracy with first time step features: {accuracy_first:.2f}')\n",
    "\n",
    "    for n_features in [1, 2, 3, 4, 5, 8, 10, 15]:\n",
    "        X_train_subset = X_train_agg.iloc[:, :n_features*2]\n",
    "        X_test_subset = X_test_agg.iloc[:, :n_features*2]\n",
    "        accuracy = evaluate_classifier(X_train_subset, X_test_subset, y_train_agg, y_test_agg)\n",
    "        print(f'Accuracy with {n_features} aggregated features: {accuracy:.2f}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
