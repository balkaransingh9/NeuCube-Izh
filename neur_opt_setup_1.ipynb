{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "rna_data = pd.read_csv(\"gene_data/rna_common_complete.csv\")\n",
    "rna_data = rna_data.sort_values(by=['sn','period']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_og_shape = rna_data.drop(['sn','group','caarms_status','period'],axis=1).values\n",
    "X_reshaped = X_og_shape.reshape(len(set(rna_data['sn'])), 3, X_og_shape.shape[1])\n",
    "labels_group = rna_data[rna_data['period'] == 24]['group'].values\n",
    "labels = [0 if i == 'C' else 1 for i in labels_group]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from neucube.utils import SNR\n",
    "from neucube.utils import interpolate\n",
    "from neucube.encoder import Delta\n",
    "\n",
    "ratios = SNR(X_reshaped[:,0,:], labels)\n",
    "top_idx = torch.argsort(ratios, descending=True)[0:20]\n",
    "X_reshaped_topidx = X_reshaped[:,:,top_idx]\n",
    "interpolated_X = interpolate(X_reshaped_topidx, num_points=104)\n",
    "\n",
    "encoder = Delta(threshold=0.008)\n",
    "X = encoder.encode_dataset(interpolated_X)\n",
    "y = torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nevergrad as ng\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from neucube.sampler import TemporalBinning\n",
    "from neucube.utils import SeparationIndex\n",
    "from tqdm import tqdm\n",
    "\n",
    "def objective_function(res_, X_stimuli, labels, sampler, params):\n",
    "    a, b, c, d = params\n",
    "    res_.update_parms(a=a, b=b, c=c, d=d)\n",
    "    out_spikes = res_.simulate(X_stimuli, mem_thr=30, train=False, verbose=False)\n",
    "    #sampler = TemporalBinning(bin_size=10)\n",
    "    state_vec = sampler.sample(out_spikes)\n",
    "    return SeparationIndex(state_vec, labels).item()\n",
    "\n",
    "def run_opt(optimizer, objective_):\n",
    "    for i in range(optimizer.budget):\n",
    "        x = optimizer.ask()\n",
    "        loss = -objective_(params=x.value)\n",
    "        optimizer.tell(x, loss)\n",
    "        if (i + 1) % 2 == 0:\n",
    "            print(f\"Iteration {i + 1}/{optimizer.budget}, Current loss: {loss}\")\n",
    "\n",
    "def train_dyanmics(reservoir_, X_, y_, sampler_):\n",
    "    parametrization = ng.p.Tuple(\n",
    "        ng.p.Array(init=reservoir_.a.cpu()),\n",
    "        ng.p.Array(init=reservoir_.b.cpu()),\n",
    "        ng.p.TransitionChoice(list(range(-65,-46)), repetitions=reservoir_.c.cpu().shape[0]),\n",
    "        ng.p.TransitionChoice(list(range(2,9)), repetitions=reservoir_.d.cpu().shape[0]),\n",
    "    )\n",
    "\n",
    "    parametrization[0].set_bounds(lower=0.01, upper=0.5)\n",
    "    parametrization[1].set_bounds(lower=0.2, upper=0.75)\n",
    "\n",
    "    optimizer = ng.optimizers.PortfolioDiscreteOnePlusOne(parametrization=parametrization, budget=350)\n",
    "    partial_objective_function = partial(objective_function, res_=reservoir_, X_stimuli=X_, labels=y_, sampler=sampler_)\n",
    "\n",
    "    run_opt(optimizer, partial_objective_function)\n",
    "    recommendation = optimizer.provide_recommendation()\n",
    "    optimal_a, optimal_b, optimal_c, optimal_d = recommendation.value\n",
    "    return recommendation.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run exp in 10 fold and allow multiple runs\n",
    "#remember to include new additions from kaggle, colab notebooks\n",
    "#run gridsearch on SVM parms in every fold\n",
    "#calc accuracy and mcc\n",
    "#save the results in a csv,pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\singh\\miniconda3\\Lib\\site-packages\\nevergrad\\parametrization\\_datalayers.py:107: NevergradRuntimeWarning: Bounds are 0.49 sigma away from each other at the closest, you should aim for at least 3 for better quality.\n",
      "  warnings.warn(\n",
      "c:\\Users\\singh\\miniconda3\\Lib\\site-packages\\nevergrad\\parametrization\\_datalayers.py:107: NevergradRuntimeWarning: Bounds are 0.55 sigma away from each other at the closest, you should aim for at least 3 for better quality.\n",
      "  warnings.warn(\n",
      "1it [01:10, 70.12s/it]c:\\Users\\singh\\miniconda3\\Lib\\site-packages\\nevergrad\\parametrization\\_datalayers.py:107: NevergradRuntimeWarning: Bounds are 0.49 sigma away from each other at the closest, you should aim for at least 3 for better quality.\n",
      "  warnings.warn(\n",
      "c:\\Users\\singh\\miniconda3\\Lib\\site-packages\\nevergrad\\parametrization\\_datalayers.py:107: NevergradRuntimeWarning: Bounds are 0.55 sigma away from each other at the closest, you should aim for at least 3 for better quality.\n",
      "  warnings.warn(\n",
      "2it [02:12, 65.76s/it]c:\\Users\\singh\\miniconda3\\Lib\\site-packages\\nevergrad\\parametrization\\_datalayers.py:107: NevergradRuntimeWarning: Bounds are 0.49 sigma away from each other at the closest, you should aim for at least 3 for better quality.\n",
      "  warnings.warn(\n",
      "c:\\Users\\singh\\miniconda3\\Lib\\site-packages\\nevergrad\\parametrization\\_datalayers.py:107: NevergradRuntimeWarning: Bounds are 0.55 sigma away from each other at the closest, you should aim for at least 3 for better quality.\n",
      "  warnings.warn(\n",
      "3it [03:13, 64.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-Fold Cross-Validation Accuracy: 0.8260869565217391\n",
      "10-Fold Cross-Validation MCC: 0.6595737421732903\n",
      "[[50 14]\n",
      " [ 6 45]]\n",
      "[0.8974358974358975, 0.8947368421052632, 0.6842105263157895]\n",
      "[0.4230217115244236, 0.8014692390706398, 0.21159842337288995]\n",
      "[tensor(0.0113), tensor(0.0435), tensor(0.0163), tensor(0.0412), tensor(0.0230), tensor(0.0112)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from neucube import IzhReservoir\n",
    "from neucube.sampler import TemporalBinning\n",
    "from neucube.utils import SeparationIndex\n",
    "\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds)\n",
    "sampler = TemporalBinning(bin_size=10)\n",
    "\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "separation_values = []\n",
    "accuracy_values = []\n",
    "mcc_values = []\n",
    "\n",
    "for train_index, test_index in tqdm(kf.split(X)):\n",
    "    X_train_fold, X_test_fold = X[train_index], X[test_index]\n",
    "    y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "\n",
    "    izh_res = IzhReservoir(inputs=X.shape[2], c=0.7, l=0.18, input_conn_prob=0.85)\n",
    "    izh_res.set_exc_parms(a=0.06, b=0.55, c=-55, d=3) #initial values\n",
    "    izh_res.set_inh_parms(a=0.1, b=0.2, c=-65, d=2) #initial values\n",
    "\n",
    "    opt_a, opt_b, opt_c, opt_d = train_dyanmics(izh_res, X_train_fold, y_train_fold, sampler)\n",
    "    izh_res.update_parms(a=opt_a, b=opt_b, c=opt_c, d=opt_d)\n",
    "    X_train_opt_spike = izh_res.simulate(X_train_fold, mem_thr=30, train=False, verbose=False)\n",
    "    X_test_opt_spike = izh_res.simulate(X_test_fold, mem_thr=30, train=False, verbose=False)\n",
    "    X_train_state_vec = sampler.sample(X_train_opt_spike)\n",
    "    X_test_state_vec = sampler.sample(X_test_opt_spike)\n",
    "\n",
    "    param_grid = {'C': [2, 3, 4, 5, 6, 7, 8], 'gamma': [0.1, 0.01, 0.001], 'kernel': ['rbf', 'linear', 'poly']}\n",
    "    svm_model = svm.SVC()\n",
    "    mcc_scorer = make_scorer(metrics.matthews_corrcoef)\n",
    "    grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=10, scoring={'accuracy': 'accuracy', 'mcc': mcc_scorer}, refit='mcc')\n",
    "    grid_search.fit(X_train_state_vec, y_train_fold)\n",
    "    y_pred = grid_search.best_estimator_.predict(X_test_state_vec)\n",
    "\n",
    "    true_labels.extend(y_test_fold)\n",
    "    predicted_labels.extend(y_pred)\n",
    "    separation_values.extend([SeparationIndex(X_train_state_vec, y_train_fold), SeparationIndex(X_test_state_vec, y_test_fold)])\n",
    "    accuracy_values.append(accuracy_score(y_test_fold, y_pred))\n",
    "    mcc_values.append(metrics.matthews_corrcoef(y_test_fold, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "mcc = metrics.matthews_corrcoef(true_labels, predicted_labels)\n",
    "print(\"10-Fold Cross-Validation Accuracy:\", accuracy)\n",
    "print(\"10-Fold Cross-Validation MCC:\", mcc)\n",
    "print(confusion_matrix(true_labels, predicted_labels))\n",
    "print(accuracy_values)\n",
    "print(mcc_values)\n",
    "print(separation_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True_Labels</th>\n",
       "      <th>Predicted_Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     True_Labels  Predicted_Labels\n",
       "0              0                 0\n",
       "1              0                 0\n",
       "2              0                 0\n",
       "3              0                 0\n",
       "4              0                 1\n",
       "..           ...               ...\n",
       "110            0                 1\n",
       "111            1                 1\n",
       "112            1                 1\n",
       "113            1                 1\n",
       "114            1                 1\n",
       "\n",
       "[115 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'True_Labels': np.array(true_labels), 'Predicted_Labels': np.array(predicted_labels)}).to_csv('results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
