{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "rna_data = pd.read_csv(\"gene_data/rna_common_complete.csv\")\n",
    "rna_data = rna_data.sort_values(by=['sn','period']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_og_shape = rna_data.drop(['sn','group','caarms_status','period'],axis=1).values\n",
    "X_reshaped = X_og_shape.reshape(len(set(rna_data['sn'])), 3, X_og_shape.shape[1])\n",
    "labels_group = rna_data[rna_data['period'] == 24]['group'].values\n",
    "labels = [0 if i == 'C' else 1 for i in labels_group]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from neucube.utils import SNR\n",
    "from neucube.utils import interpolate\n",
    "from neucube.encoder import Delta\n",
    "\n",
    "ratios = SNR(X_reshaped[:,0,:], labels)\n",
    "top_idx = torch.argsort(ratios, descending=True)[0:20]\n",
    "X_reshaped_topidx = X_reshaped[:,:,top_idx]\n",
    "interpolated_X = interpolate(X_reshaped_topidx, num_points=104)\n",
    "\n",
    "encoder = Delta(threshold=0.008)\n",
    "X = encoder.encode_dataset(interpolated_X)\n",
    "y = torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nevergrad as ng\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from neucube.sampler import TemporalBinning\n",
    "from neucube.utils import SeparationIndex\n",
    "from tqdm import tqdm\n",
    "\n",
    "def objective_function(res_, X_stimuli, labels, sampler, params):\n",
    "    a, b, c, d = params\n",
    "    res_.update_parms(a=a, b=b, c=c, d=d)\n",
    "    out_spikes = res_.simulate(X_stimuli, mem_thr=30, train=False, verbose=False)\n",
    "    #sampler = TemporalBinning(bin_size=10)\n",
    "    state_vec = sampler.sample(out_spikes)\n",
    "    return SeparationIndex(state_vec, labels).item()\n",
    "\n",
    "def run_opt(optimizer, objective_):\n",
    "    for i in range(optimizer.budget):\n",
    "        x = optimizer.ask()\n",
    "        loss = -objective_(params=x.value)\n",
    "        optimizer.tell(x, loss)\n",
    "        if (i + 1) % 2 == 0:\n",
    "            print(f\"Iteration {i + 1}/{optimizer.budget}, Current loss: {loss}\")\n",
    "\n",
    "def train_dyanmics(reservoir_, X_, y_, sampler_):\n",
    "    parametrization = ng.p.Tuple(\n",
    "        ng.p.Array(init=reservoir_.a.cpu()),\n",
    "        ng.p.Array(init=reservoir_.b.cpu()),\n",
    "        ng.p.TransitionChoice(list(range(-65,-46)), repetitions=reservoir_.c.cpu().shape[0]),\n",
    "        ng.p.TransitionChoice(list(range(2,9)), repetitions=reservoir_.d.cpu().shape[0]),\n",
    "    )\n",
    "\n",
    "    parametrization[0].set_bounds(lower=0.01, upper=0.5)\n",
    "    parametrization[1].set_bounds(lower=0.2, upper=0.75)\n",
    "\n",
    "    optimizer = ng.optimizers.PortfolioDiscreteOnePlusOne(parametrization=parametrization, budget=1)\n",
    "    partial_objective_function = partial(objective_function, res_=reservoir_, X_stimuli=X_, labels=y_, sampler=sampler_)\n",
    "\n",
    "    run_opt(optimizer, partial_objective_function)\n",
    "    recommendation = optimizer.provide_recommendation()\n",
    "    optimal_a, optimal_b, optimal_c, optimal_d = recommendation.value\n",
    "    return recommendation.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run exp in 10 fold and allow multiple runs\n",
    "#remember to include new additions from kaggle, colab notebooks\n",
    "#run gridsearch on SVM parms in every fold\n",
    "#calc accuracy and mcc\n",
    "#save the results in a csv,pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]c:\\Users\\singh\\miniconda3\\Lib\\site-packages\\nevergrad\\parametrization\\_datalayers.py:107: NevergradRuntimeWarning: Bounds are 0.49 sigma away from each other at the closest, you should aim for at least 3 for better quality.\n",
      "  warnings.warn(\n",
      "c:\\Users\\singh\\miniconda3\\Lib\\site-packages\\nevergrad\\parametrization\\_datalayers.py:107: NevergradRuntimeWarning: Bounds are 0.55 sigma away from each other at the closest, you should aim for at least 3 for better quality.\n",
      "  warnings.warn(\n",
      "0it [00:02, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m izh_res\u001b[38;5;241m.\u001b[39mset_exc_parms(a\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.06\u001b[39m, b\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.55\u001b[39m, c\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m55\u001b[39m, d\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m) \u001b[38;5;66;03m#initial values\u001b[39;00m\n\u001b[0;32m     27\u001b[0m izh_res\u001b[38;5;241m.\u001b[39mset_inh_parms(a\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, b\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, c\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m65\u001b[39m, d\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m) \u001b[38;5;66;03m#initial values\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m opt_a, opt_b, opt_c, opt_d \u001b[38;5;241m=\u001b[39m train_dyanmics(izh_res, X_train_fold, y_train_fold, sampler)\n\u001b[0;32m     30\u001b[0m izh_res\u001b[38;5;241m.\u001b[39mupdate_parms(a\u001b[38;5;241m=\u001b[39mopt_a, b\u001b[38;5;241m=\u001b[39mopt_b, c\u001b[38;5;241m=\u001b[39mopt_c, d\u001b[38;5;241m=\u001b[39mopt_d)\n\u001b[0;32m     31\u001b[0m X_train_opt_spike \u001b[38;5;241m=\u001b[39m izh_res\u001b[38;5;241m.\u001b[39msimulate(X_train_fold, mem_thr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[11], line 38\u001b[0m, in \u001b[0;36mtrain_dyanmics\u001b[1;34m(reservoir_, X_, y_, sampler_)\u001b[0m\n\u001b[0;32m     35\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m ng\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mPortfolioDiscreteOnePlusOne(parametrization\u001b[38;5;241m=\u001b[39mparametrization, budget\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     36\u001b[0m partial_objective_function \u001b[38;5;241m=\u001b[39m partial(objective_function, res_\u001b[38;5;241m=\u001b[39mreservoir_, X_stimuli\u001b[38;5;241m=\u001b[39mX_, labels\u001b[38;5;241m=\u001b[39my_, sampler\u001b[38;5;241m=\u001b[39msampler_)\n\u001b[1;32m---> 38\u001b[0m run_opt(optimizer, partial_objective_function)\n\u001b[0;32m     39\u001b[0m recommendation \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mprovide_recommendation()\n\u001b[0;32m     40\u001b[0m optimal_a, optimal_b, optimal_c, optimal_d \u001b[38;5;241m=\u001b[39m recommendation\u001b[38;5;241m.\u001b[39mvalue\n",
      "Cell \u001b[1;32mIn[11], line 19\u001b[0m, in \u001b[0;36mrun_opt\u001b[1;34m(optimizer, objective_)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(optimizer\u001b[38;5;241m.\u001b[39mbudget):\n\u001b[0;32m     18\u001b[0m     x \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mask()\n\u001b[1;32m---> 19\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mobjective_(params\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mvalue)\n\u001b[0;32m     20\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mtell(x, loss)\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[1;32mIn[11], line 11\u001b[0m, in \u001b[0;36mobjective_function\u001b[1;34m(res_, X_stimuli, labels, sampler, params)\u001b[0m\n\u001b[0;32m      9\u001b[0m a, b, c, d \u001b[38;5;241m=\u001b[39m params\n\u001b[0;32m     10\u001b[0m res_\u001b[38;5;241m.\u001b[39mupdate_parms(a\u001b[38;5;241m=\u001b[39ma, b\u001b[38;5;241m=\u001b[39mb, c\u001b[38;5;241m=\u001b[39mc, d\u001b[38;5;241m=\u001b[39md)\n\u001b[1;32m---> 11\u001b[0m out_spikes \u001b[38;5;241m=\u001b[39m res_\u001b[38;5;241m.\u001b[39msimulate(X_stimuli, mem_thr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#sampler = TemporalBinning(bin_size=10)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m state_vec \u001b[38;5;241m=\u001b[39m sampler\u001b[38;5;241m.\u001b[39msample(out_spikes)\n",
      "File \u001b[1;32mc:\\Users\\singh\\Documents\\GitHub\\NeuCube-Izh\\neucube\\IZHreservoir.py:111\u001b[0m, in \u001b[0;36mIzhReservoir.simulate\u001b[1;34m(self, X, mem_thr, dt, train, learning_rule, verbose)\u001b[0m\n\u001b[0;32m    108\u001b[0m mem_poten[thres_met] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc[thres_met]\n\u001b[0;32m    109\u001b[0m u_recvr[thres_met] \u001b[38;5;241m=\u001b[39m u_recvr[thres_met] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md[thres_met]\n\u001b[1;32m--> 111\u001b[0m spike_latent\u001b[38;5;241m.\u001b[39mfill_(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    112\u001b[0m spike_latent[thres_met] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    113\u001b[0m spike_rec[s, t, :] \u001b[38;5;241m=\u001b[39m spike_latent\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from neucube import IzhReservoir\n",
    "from neucube.sampler import TemporalBinning\n",
    "from neucube.utils import SeparationIndex\n",
    "\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds)\n",
    "sampler = TemporalBinning(bin_size=10)\n",
    "\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "separation_values = []\n",
    "accuracy_values = []\n",
    "mcc_values = []\n",
    "\n",
    "for train_index, test_index in tqdm(kf.split(X)):\n",
    "    X_train_fold, X_test_fold = X[train_index], X[test_index]\n",
    "    y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "\n",
    "    izh_res = IzhReservoir(inputs=X.shape[2], c=0.7, l=0.18, input_conn_prob=0.85)\n",
    "    izh_res.set_exc_parms(a=0.06, b=0.55, c=-55, d=3) #initial values\n",
    "    izh_res.set_inh_parms(a=0.01, b=0.2, c=-65, d=8) #initial values\n",
    "\n",
    "    opt_a, opt_b, opt_c, opt_d = train_dyanmics(izh_res, X_train_fold, y_train_fold, sampler)\n",
    "    izh_res.update_parms(a=opt_a, b=opt_b, c=opt_c, d=opt_d)\n",
    "    X_train_opt_spike = izh_res.simulate(X_train_fold, mem_thr=30, train=False, verbose=False)\n",
    "    X_test_opt_spike = izh_res.simulate(X_test_fold, mem_thr=30, train=False, verbose=False)\n",
    "    X_train_state_vec = sampler.sample(X_train_opt_spike)\n",
    "    X_test_state_vec = sampler.sample(X_test_opt_spike)\n",
    "\n",
    "    param_grid = {'C': [2, 3, 4, 5, 6, 7, 8], 'gamma': [0.1, 0.01, 0.001], 'kernel': ['rbf', 'linear', 'poly']}\n",
    "    svm_model = svm.SVC()\n",
    "    mcc_scorer = make_scorer(metrics.matthews_corrcoef)\n",
    "    grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=10, scoring={'accuracy': 'accuracy', 'mcc': mcc_scorer}, refit='mcc')\n",
    "    grid_search.fit(X_train_state_vec, y_train_fold)\n",
    "    y_pred = grid_search.best_estimator_.predict(X_test_state_vec)\n",
    "\n",
    "    true_labels.extend(y_test_fold)\n",
    "    predicted_labels.extend(y_pred)\n",
    "    separation_values.extend([SeparationIndex(X_train_state_vec, y_train_fold), SeparationIndex(X_test_state_vec, y_test_fold)])\n",
    "    accuracy_values.append(accuracy_score(y_test_fold, y_pred))\n",
    "    mcc_values.append(metrics.matthews_corrcoef(y_test_fold, y_pred))\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(\"10-Fold Cross-Validation Accuracy:\", accuracy)\n",
    "print(confusion_matrix(true_labels, predicted_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
