{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "rna_data = pd.read_csv(\"gene_data/rna_common_complete.csv\")\n",
    "rna_data = rna_data.sort_values(by=['sn','period']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_og_shape = rna_data.drop(['sn','group','caarms_status','period'],axis=1).values\n",
    "X_reshaped = X_og_shape.reshape(len(set(rna_data['sn'])), 3, X_og_shape.shape[1])\n",
    "labels_group = rna_data[rna_data['period'] == 24]['group'].values\n",
    "labels = [0 if i == 'C' else 1 for i in labels_group]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from neucube.utils import SNR\n",
    "from neucube.utils import interpolate\n",
    "from neucube.encoder import Delta\n",
    "\n",
    "ratios = SNR(X_reshaped[:,0,:], labels)\n",
    "top_idx = torch.argsort(ratios, descending=True)[0:20]\n",
    "X_reshaped_topidx = X_reshaped[:,:,top_idx]\n",
    "interpolated_X = interpolate(X_reshaped_topidx, num_points=104)\n",
    "\n",
    "encoder = Delta(threshold=0.008)\n",
    "X = encoder.encode_dataset(interpolated_X)\n",
    "y = torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nevergrad as ng\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from neucube.sampler import TemporalBinning\n",
    "from neucube.utils import SeparationIndex\n",
    "from tqdm import tqdm\n",
    "\n",
    "neuron_parm_dict = { \n",
    "    'rs' : {'a': 0.02, 'b': 0.2, 'c': -65, 'd': 8}, \n",
    "    'ch' : {'a': 0.02, 'b': 0.55, 'c': -45, 'd': 4},\n",
    "    'ib' : {'a': 0.06, 'b': 0.55, 'c': -55, 'd': 3},\n",
    "}\n",
    "\n",
    "def objective_function(res_, X_stimuli, labels, params, sampler):\n",
    "    a, b, c, d = [torch.tensor(list(map(lambda x: neuron_parm_dict[x][i], params))) for i in ['a', 'b', 'c', 'd']]\n",
    "    res_.update_parms(a=a, b=b, c=c, d=d)\n",
    "    out_spikes = res_.simulate(X_stimuli, mem_thr=30, train=False, verbose=True)\n",
    "    state_vec = sampler.sample(out_spikes)\n",
    "    return SeparationIndex(state_vec, labels).item()\n",
    "\n",
    "def run_opt(optimizer, objective_):\n",
    "    for i in range(optimizer.budget):\n",
    "        x = optimizer.ask()\n",
    "        loss = -objective_(params=x.value)\n",
    "        optimizer.tell(x, loss)\n",
    "        if (i + 1) % 2 == 0:\n",
    "            print(f\"Iteration {i + 1}/{optimizer.budget}, Current loss: {loss}\")\n",
    "\n",
    "def train_dyanmics(reservoir_, X_, y_, sampler_):\n",
    "    parametrization = ng.p.Choice(['rs','ch','ib'], repetitions=reservoir_.n_neurons)\n",
    "\n",
    "    optimizer = ng.optimizers.NoisyDiscreteOnePlusOne(parametrization=parametrization, budget=5)\n",
    "    partial_objective_function = partial(objective_function, res_=reservoir_, X_stimuli=X_, labels=y_, sampler=sampler_)\n",
    "\n",
    "    run_opt(optimizer, partial_objective_function)\n",
    "    recommendation = optimizer.provide_recommendation()\n",
    "    return recommendation.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [00:15<00:00,  4.94it/s]\n",
      "100%|██████████| 76/76 [00:15<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2/5, Current loss: -0.011109150014817715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [00:15<00:00,  4.77it/s]\n",
      "100%|██████████| 76/76 [00:15<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4/5, Current loss: -0.011141764931380749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [00:16<00:00,  4.74it/s]\n",
      "100%|██████████| 77/77 [00:15<00:00,  4.82it/s]\n",
      "100%|██████████| 77/77 [00:16<00:00,  4.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2/5, Current loss: -0.016034912317991257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:15<00:00,  4.84it/s]\n",
      "100%|██████████| 77/77 [00:17<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4/5, Current loss: -0.01627284660935402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:16<00:00,  4.76it/s]\n",
      "100%|██████████| 77/77 [00:15<00:00,  4.87it/s]\n",
      "100%|██████████| 77/77 [00:16<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2/5, Current loss: -0.021958502009510994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:17<00:00,  4.39it/s]\n",
      "100%|██████████| 77/77 [00:17<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4/5, Current loss: -0.022191546857357025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:17<00:00,  4.50it/s]\n",
      "3it [06:37, 132.62s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from neucube import IzhReservoir\n",
    "from neucube.sampler import TemporalBinning\n",
    "from neucube.utils import SeparationIndex\n",
    "\n",
    "num_folds = 3\n",
    "kf = KFold(n_splits=num_folds)\n",
    "sampler = TemporalBinning(bin_size=10)\n",
    "\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "separation_values = []\n",
    "accuracy_values = []\n",
    "mcc_values = []\n",
    "\n",
    "for train_index, test_index in tqdm(kf.split(X)):\n",
    "    X_train_fold, X_test_fold = X[train_index], X[test_index]\n",
    "    y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "\n",
    "    izh_res = IzhReservoir(inputs=X.shape[2], c=0.7, l=0.18, input_conn_prob=0.85)\n",
    "    init_n_type = np.random.choice(['rs','ch','ib'], izh_res.n_neurons, replace=True)\n",
    "    init_a, init_b, init_c, init_d = [\n",
    "        torch.tensor(list(map(lambda x: neuron_parm_dict[x][i], init_n_type))) for i in ['a', 'b', 'c', 'd']]\n",
    "    izh_res.update_parms(a=init_a, b=init_b, c=init_c, d=init_d)\n",
    "\n",
    "    # izh_res.set_exc_parms(a=0.06, b=0.55, c=-55, d=3) #initial values\n",
    "    # izh_res.set_inh_parms(a=0.1, b=0.2, c=-65, d=2) #initial values\n",
    "\n",
    "    opt_parms = train_dyanmics(izh_res, X_train_fold, y_train_fold, sampler)\n",
    "    opt_a, opt_b, opt_c, opt_d = [\n",
    "        torch.tensor(list(map(lambda x: neuron_parm_dict[x][i], opt_parms))) for i in ['a', 'b', 'c', 'd']]\n",
    "    izh_res.update_parms(a=opt_a, b=opt_b, c=opt_c, d=opt_d)\n",
    "    X_train_opt_spike = izh_res.simulate(X_train_fold, mem_thr=30, train=False, verbose=False)\n",
    "    X_test_opt_spike = izh_res.simulate(X_test_fold, mem_thr=30, train=False, verbose=False)\n",
    "    X_train_state_vec = sampler.sample(X_train_opt_spike)\n",
    "    X_test_state_vec = sampler.sample(X_test_opt_spike)\n",
    "\n",
    "    param_grid = {'C': [2, 3, 4, 5, 6, 7, 8], 'gamma': [0.1, 0.01, 0.001], 'kernel': ['rbf', 'linear', 'poly']}\n",
    "    svm_model = svm.SVC()\n",
    "    mcc_scorer = make_scorer(metrics.matthews_corrcoef)\n",
    "    grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=10, scoring={'accuracy': 'accuracy', 'mcc': mcc_scorer}, refit='mcc')\n",
    "    grid_search.fit(X_train_state_vec, y_train_fold)\n",
    "    y_pred = grid_search.best_estimator_.predict(X_test_state_vec)\n",
    "\n",
    "    true_labels.extend(y_test_fold)\n",
    "    predicted_labels.extend(y_pred)\n",
    "    separation_values.extend([SeparationIndex(X_train_state_vec, y_train_fold), SeparationIndex(X_test_state_vec, y_test_fold)])\n",
    "    accuracy_values.append(accuracy_score(y_test_fold, y_pred))\n",
    "    mcc_values.append(metrics.matthews_corrcoef(y_test_fold, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-Fold Cross-Validation Accuracy: 0.808695652173913\n",
      "10-Fold Cross-Validation MCC: 0.6245548223441452\n",
      "[[49 15]\n",
      " [ 7 44]]\n",
      "[0.8974358974358975, 0.8421052631578947, 0.6842105263157895]\n",
      "[0.4230217115244236, 0.6899094182476204, 0.21159842337288995]\n",
      "[tensor(0.0111), tensor(0.0418), tensor(0.0163), tensor(0.0400), tensor(0.0222), tensor(0.0116)]\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "mcc = metrics.matthews_corrcoef(true_labels, predicted_labels)\n",
    "print(\"10-Fold Cross-Validation Accuracy:\", accuracy)\n",
    "print(\"10-Fold Cross-Validation MCC:\", mcc)\n",
    "print(confusion_matrix(true_labels, predicted_labels))\n",
    "print(accuracy_values)\n",
    "print(mcc_values)\n",
    "print(separation_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'True_Labels': np.array(true_labels), 'Predicted_Labels': np.array(predicted_labels)}).to_csv('results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
